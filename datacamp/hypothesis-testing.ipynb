{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd10bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating p-values\n",
    "prop_child_samp = (stack_overflow['age_first_code_cut'] == 'child').mean()\n",
    "#hypothesizedd value\n",
    "prop_child_hyp = 0.35\n",
    "std_error = np.std(first_code_boot_distn,ddof=1)\n",
    "z_score = (prop_child_samp-prop_child_hyp)/std_error\n",
    "#right-tailed\n",
    "from scipy.stats import norm\n",
    "1 - norm.cdf(z_score,loc=0, scale=1)\n",
    "\n",
    "#if p_value <= alpha; Reject H-zero in favor of H-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = 0.01\n",
    "import pingouin\n",
    "pingouin.ttest(x=repub_votes_08_12_small['repub_percent_08'],\n",
    "              y=repub_votes_08_12_small['repub_percent_12'],\n",
    "              paired=True,\n",
    "              alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "285bba1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 5., 2., 4., 3.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,15,3,10,6]\n",
    "from scipy.stats import rankdata\n",
    "rankdata(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dee291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non- parametric tests\n",
    "#Wilcoxon-signed rank test(Step 1)\n",
    "repub_votes_small['diff'] = repub_votes_small['repub_percent_08']-repub_votes_small['repub_percent_12']\n",
    "print(repub_votes_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "repub_votes_small['abs_diff'] = repub_votes_small['diff'].abs\n",
    "print(repub_votes_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739dcd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "from scipy.stats import rankdata\n",
    "repub_votes_small['rank_abs_diff'] = rankdata(repub_votes_small['abs_diff'])\n",
    "print(repub_votes_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e3ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4\n",
    "T_minus = 1+4 + 5+ 2+3\n",
    "T_plus = 0\n",
    "W = np.min([T_minus,T_plus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66582e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation with pingouin\n",
    "alpha = 0.01\n",
    "pingouin.wilcoxon(x=repub_votes_08_12_small['repub_percent_08'],\n",
    "              y=repub_votes_08_12_small['repub_percent_12'],\n",
    "              alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b743db",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Non-parametric ANOVA and unpaired t-tests\n",
    "#Wilcoxon-Mann-Whitney test setup\n",
    "age_vs_comp = stack_overflow[['converted_comp','age_first_code_cut']]\n",
    "age_vs_comp_wide = age_vs_comp.pivot(columns= 'age_first_code_cut',\n",
    "                                    values='converted_comp')\n",
    "alpha=0.01\n",
    "pingouin.mwu(x=age_vs_comp_wide['child'],\n",
    "            y=age_vs_comp_wide['adult'],\n",
    "            alternative='greater')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a8549b",
   "metadata": {},
   "source": [
    "# Kruskal-Wallis Test\n",
    "### KW --> ANOVA\n",
    "### WMW --> t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09614eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "pingouin.kruskal(data=stack_overflow,\n",
    "                dv='converted_comp',\n",
    "                between='job_sat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0285f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the weight_kilograms and late columns\n",
    "weight_vs_late = late_shipments[['weight_kilograms','late']]\n",
    "\n",
    "# Convert weight_vs_late into wide format\n",
    "weight_vs_late_wide = weight_vs_late.pivot(columns='late', \n",
    "                                           values='weight_kilograms')\n",
    "\n",
    "\n",
    "# Run a two-sided Wilcoxon-Mann-Whitney test on weight_kilograms vs. late\n",
    "wmw_test = pingouin.mwu(x=weight_vs_late_wide['No'],y=weight_vs_late_wide['Yes'],\n",
    "alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ef316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a Kruskal-Wallis test on weight_kilograms vs. shipment_mode\n",
    "kw_test = pingouin.kruskal(data=late_shipments,\n",
    "dv='weight_kilograms',between='shipment_mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81657ebd",
   "metadata": {},
   "source": [
    "# Testing Proprtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H_zero : proportion of Stack Overflow users under 30 = 0.5\n",
    "H_alt : proportion of Stack Overflow users under 30 =/ 0.5\n",
    "alpha = 0.01\n",
    "stack_overflow['age_cat'].value_counts(normalize=True)\n",
    "p_hat = (stack_overflow['age_cat'] == 'Under 30').mean()\n",
    "n = len(stack_overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b350431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the z-score\n",
    "import numpy as np\n",
    "numerator = p_hat - p_zero\n",
    "denominator = np.sqrt(p_zero * (1-p_zero)/n)\n",
    "z = numerator/ denominator\n",
    "\n",
    "\n",
    "#for left-tailed alternative hypothesis, transform z-score to p-value using cdf\n",
    "from scipy.stats import norm\n",
    "\n",
    "#left-tailed --> 'less than'\n",
    "p_value = norm.cdf(z_score)\n",
    "\n",
    "#right-tailed --> 'greater than'\n",
    "p_value = 1-norm.cdf(z_score)\n",
    "\n",
    "#two-tailed --> 'not equal'\n",
    "p_value = norm.cdf(-z_score) + 1 + norm.cdf(z_score)\n",
    "p_value = 2 * (1-norm.cdf(z_score))\n",
    "\n",
    "p_value <= alpha i strue , so we reject the null hypothesis that mean of programmers under 30 is less than 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cdfff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesize that the proportion of late shipments is 6%\n",
    "p_0 = 0.06\n",
    "\n",
    "# Calculate the sample proportion of late shipments\n",
    "p_hat = (late_shipments['late'] == \"Yes\").mean()\n",
    "\n",
    "# Calculate the sample size\n",
    "n = len(late_shipments)\n",
    "\n",
    "# Calculate the numerator and denominator of the test statistic\n",
    "numerator = p_hat - p_0\n",
    "denominator = np.sqrt(p_0 * (1 - p_0) / n)\n",
    "\n",
    "# Calculate the test statistic\n",
    "z_score = numerator / denominator\n",
    "\n",
    "# Calculate the p-value from the z-score\n",
    "p_value = 1-norm.cdf(z_score)\n",
    "\n",
    "# Print the p-value\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db61474",
   "metadata": {},
   "source": [
    "# Two Sample Proportion Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3986138",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_0: p_>30 - p_sub30 = 0\n",
    "H_alt: p_>30 - p_sub30 =/ 0  \n",
    "alpha = 0.05\n",
    "\n",
    "#p_hat is a weighted mean of p_>30 and p_sub30\n",
    "p_hats = stack_overflow.groupby(\"age_cat\")['hobbyist'].value_counts(normalize=True)\n",
    "n = stack_overflow.groupby(\"age_cat\")['hobbyist'].count()\n",
    "\n",
    "p_hat_atleast30 = p_hats[('At Least 30',\"Yes\")]\n",
    "p_hat_under30 = p_hats[('Under 30',\"Yes\")]\n",
    "print(p_hat_atleast30, p_hat_under30)\n",
    "\n",
    "n_atleast30 = n['At Least 30']\n",
    "n_under30 = n['Under 30']\n",
    "\n",
    "\n",
    "p_hat = (n_atleast30 * p_hat_atleast30 + n_under30*p_hat_under30)/(n_atleast30 + n_under30)\n",
    "std_error = np.sqrt(p_hat*(1-p_hat)/n_atleast30 + p_hat*(1-p_hat)/n_under30)\n",
    "z_score = (p_hat_atleast30-p_hat_under30) / std_error\n",
    "print(z_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ff31c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.223691463320559 2.403330142685068e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#using proportions_ztest()\n",
    "#stack_overflow.groupby(\"age_cat\")['hobbyist'].value_counts()\n",
    "n_hobbyist = np.array([812,1021])\n",
    "n_rows = np.array([812+238, 1021+190])\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "z_score, p_value = proportions_ztest(count=n_hobbyist, nobs=n_rows,\n",
    "                                    alternative=\"two-sided\")\n",
    "print(z_score, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8983d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_value is smaller than the significance level so we conclude taht there is a significant different between hobbyist proportions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2346e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pooled estimate of the population proportion\n",
    "p_hat = (p_hats[\"reasonable\"] * ns[\"reasonable\"] + p_hats[\"expensive\"] * ns[\"expensive\"]) / (ns[\"reasonable\"] + ns[\"expensive\"])\n",
    "\n",
    "# Calculate p_hat one minus p_hat\n",
    "p_hat_times_not_p_hat = p_hat * (1 - p_hat)\n",
    "\n",
    "# Divide this by each of the sample sizes and then sum\n",
    "p_hat_times_not_p_hat_over_ns = p_hat_times_not_p_hat / ns[\"expensive\"] + p_hat_times_not_p_hat / ns[\"reasonable\"]\n",
    "\n",
    "# Calculate the standard error\n",
    "std_error = np.sqrt(p_hat_times_not_p_hat_over_ns)\n",
    "\n",
    "# Calculate the z-score\n",
    "z_score = (p_hats[\"expensive\"] - p_hats[\"reasonable\"]) / std_error\n",
    "\n",
    "# Calculate the p-value from the z-score\n",
    "p_value = 1-norm.cdf(z_score)\n",
    "\n",
    "# Print p_value\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ea492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the late column values for each freight_cost_group\n",
    "late_by_freight_cost_group = late_shipments.groupby(\"freight_cost_group\")['late'].value_counts()\n",
    "\n",
    "# Create an array of the \"Yes\" counts for each freight_cost_group\n",
    "success_counts = np.array([45, 16])\n",
    "\n",
    "# Create an array of the total number of rows in each freight_cost_group\n",
    "n = np.array([545, 439+16])\n",
    "\n",
    "# Run a z-test on the two proportions\n",
    "stat, p_value = proportions_ztest(count=success_counts, nobs=n,\n",
    "                                    alternative=\"larger\")\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(stat, p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
